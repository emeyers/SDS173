{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseball Lab 7\n",
    "\n",
    "Welcome to the seventh baseball lab.  This lab is due by  **Monday, April 12th at 11:30pm**. \n",
    "\n",
    "As always, you are welcome to work with others on the lab, but if you do work with others after class, please note on the reflection quiz who you worked with. If you have questions about the homework please use [Ed discussions](https://edstem.org/us/courses/4202/discussion/) so that everyone can benefit from your question. Additionally, please answer questions others raise on Ed discussions. Finally, please feel free to attend Neel's and my office hours for additional help. \n",
    "\n",
    "\n",
    "#### Today's Baseball Lab\n",
    "\n",
    "In today's exercises, you'll get practice:\n",
    "\n",
    "1. Running parametric hypothesis tests for a single proportion\n",
    "2. Running parametric hypothesis tests two compare two means\n",
    "\n",
    "Reading that will be useful for solving the problems below are chapters 11-14 from the class textbook. We will go over constructing bootstrap confidence intervals in Python next class.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages that will be used in this lab\n",
    "\n",
    "from datascience import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import binom\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "np.random.seed(173)\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Parametric hypothesis tests for a single proportion - was A-Rod's OBP just .300 revisited\n",
    "\n",
    "In lab 6 you ran a hypothesis test to examine if Alex Rodriguez's (A-Rod) OBP *ability* (π) was 0.300. In particular, you tried to answer the following question: \n",
    "\n",
    "\"In 2012, Alex Rodriguez (A-Rod) had a .353 on-base percentage (OBP) based on 529 plate appearances. \n",
    "\n",
    "Let us denote this observed OBP performance with the symbol p̂. This observed performance (p̂) is due to both:\n",
    "\n",
    "a) A-Rod’s innate ability/skill (π)\n",
    "\n",
    "b) Luck, randomness, chance  \n",
    "\n",
    "So how good is A-Rod really? Is it plausible that A-Rod’s OBP ability π was really .300 and he just got lucky to get a p̂ of .353?\"\n",
    "\n",
    "##### Running the hypothesis test using simulations\n",
    "\n",
    "To address this question, on homework 6 you ran the hypothesis test using the following steps: \n",
    "\n",
    "1. You stated the null and alternative hypotheses. \n",
    "\n",
    "2. You created a *null distribution* by simulating A-Rod's *performance statistics* (p̂) that one would expect to get if A-Rod's true ability was 0.300; i.e., you used computer simulations to generate a *null distribution* of p̂'s that were consistent with the null hypothesis. To do this you used several functions in Python from the datascience package.\n",
    "\n",
    "3. You then calculated the p-value, which was the proportion of statistics in the null distribution that was as great or greater than A-Rod's actual OBP of p̂ = 0.353. The p-value you got was around 0.0047. Since this p-value was small (say less than 0.05) you rejected the null hypothesis and accepted the fact that A-Rod's OBP ability was greater than 0.300. \n",
    "\n",
    "Let us revisit this hypothesis test, but instead of creating a null distribution using computational simulations in step 2, we will instead use a mathematical function (the binomial distribution) as the null distribution. Apart from this step, the rest of the hypothesis test will be the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1: Stating the null and alternative hypothesis (again)\n",
    "\n",
    "To start this analysis, let's make sure we remember what we did on lab 6 by once again stating the null and alternative hypotheses in symbols and words. Also, write down the observed statistic value using the appropriate symbol. Finally, in the code section create a name `observed_obp` and set it to A-Rod's observed OBP as measured by his actual performance in 2012, and create a name `num_times_ARod_on_base` that has the number of times A-Rod got on base (rounded to the nearest integer). Report what these values are as well. Hint: If you forgot how to do this look at your answers from homework 6!\n",
    "\n",
    "\n",
    "**Exercise 1.1 (2 points)**: Please state the null and alternative hypothesis again to start the analysis.\n",
    "\n",
    "\n",
    "**Answer**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2: Using the binomial distribution as the null distribution \n",
    "\n",
    "As discussed in our online class, we can use the binomial distribution for the null distribution in step 2 of our hypothesis test. Apart from this substitution, the rest of the hypothesis test is the same. \n",
    "\n",
    "The binomial *density function* is a mathematical function $f(k)$ that can be used to model the probability of getting *k* \"successes\" given that there were *n* trials and the probability of success on each trial is *π*.\n",
    "\n",
    "The binomial density function has the following form: \n",
    "\n",
    "$f(k) = {n \\choose k}\\pi^k(1-\\pi)^{n-k}$  \n",
    "\n",
    "for k in {0, 1,..., n} \n",
    "\n",
    "Also, note that the \"n choose k\" function is given by the formula: ${n \\choose k} = \\frac{n!}{k!(n-k)!}$\n",
    "\n",
    "For the case of modeling A-Rod's OBP, *k* would refer to his performance in terms of the *number of times he got on base*, n is the number of plate appearances, and $\\pi$ is his ability. \n",
    "\n",
    "**Exercise 1.2 (4 points)**: If we were to use the binomial density function for the null distribution in the A-Rod example, what would n and π be? \n",
    "\n",
    "**Answers**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.3:  Plotting the null distribution\n",
    "\n",
    "Let us now plot what a binomial null distribution would look like for modeling the A-Rod's OBP. To do this we can use the `binom.pdf(k_values, n, p)` function from the `scipy` package, where the arguments to this function are: \n",
    "\n",
    "1. k_values: a numpy ndarray of integer values - this array can be created using the np.arange() function\n",
    "2. n: the number of trials\n",
    "3. p: the probability of success on each trial (i.e., p is what we have been calling $\\pi$)\n",
    "\n",
    "This function will return an ndarray that is the same length as k_values but contains the probability of getting each value for the values given in the *k_values* ndarray input argument. \n",
    "\n",
    "We can then plot this function using the matplotlib `plt.plot(x, y)` function. \n",
    "\n",
    "**Exercise 1.3 (7 points):** Create the appropriate null distribution for testing whether A-Rod's OBP ability is 0.300 and save this distribution to a name called `arod_null_binom_pdf`. To do this, first create an ndarray called `k_values` that has the full range of possible values that the binomial function is defined over. Then pass this `k_values` ndarray along with the values of n and pi to the `binom.pdf()` function. Finally plot this distribution. When creating your plot, make sure the values on the x-axis are proportions (p̂'s) rather than counts. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4:  Calculating the p-value\n",
    "\n",
    "Now let's use this null distribution to get the p-value. To do this we need to calculate the area of the null distribution that is greater than the observed statistic which we can do using the following steps: \n",
    "\n",
    "1. Use the `k_values` ndarray and the name `num_times_ARod_on_base` to get a vector of booleans that are true for all values k that are as great or greater than the number of times A-Rod got on base. Save this ndarray of booleans to the name `p_value_inds`.\n",
    "\n",
    "2. Use the `p_value_inds` ndarray along with the `arod_null_binom_pdf` null distribution to get all the values in the null distribution that are as great or greater than the observed statistic. Hint: you can extract values from an ndarray `my_array` and a set of indices `my_inds` using the syntax `my_array[my_inds]`.\n",
    "\n",
    "3. Sum the probability values in the tail of the null distribution to get the p-value and report what the p-value is.  \n",
    "\n",
    "\n",
    "**Exercise 1.4 (7 points):** Please calculate the p-value in the code section below and report what it is in the answer section. \n",
    "\n",
    "\n",
    "**Answer**: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5:  Make a decision\n",
    "\n",
    "\n",
    "**Exercise 1.5 (5 points):** Based on the p-value you got above, does it seem plausible that A-Rod's true OBP ability is .300? Also, is the p-value that you got similar to the p-value you got in lab 6 when you used simulations? \n",
    "\n",
    "\n",
    "**Answers:** \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Parametric hypothesis tests for two means - The number of triples in the AL vs. NL revisited\n",
    "\n",
    "On part 2 of lab 6, you examined the question of whether more triples hit (on average) by teams in the American League compared to teams in the National League. Let's revisit this question but use a parametric hypothesis test. In particular, we will run a \"t-test\", where our statistic of interest is a t-statistic, and our null distribution is given by a t-distribution. \n",
    "\n",
    "The code below loads the data and creates the `teams_2000` table, which has the data from seasons since 2000, which we will use for this exercise. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = Table.read_table('https://raw.githubusercontent.com/emeyers/SDS173/master/data/Teams.csv')  \n",
    "\n",
    "teams_2000 = teams.where('yearID', are.above(1999))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1:  Stating the null and alternative hypothesis\n",
    "\n",
    "We can run *any* hypothesis test using the same 5 steps we have discussed in class. These steps are: \n",
    "\n",
    "1. State the null and alternative hypothesses.\n",
    "\n",
    "2. Calculate the statistic of interest.\n",
    "\n",
    "3. Create a null distribution.\n",
    "\n",
    "4. Calculate the p-value.\n",
    "\n",
    "5. Make a judgment. \n",
    "\n",
    "\n",
    "Let's start with step 1 now!\n",
    "\n",
    "\n",
    "**Exercise 2.1 (2 points):**  Please start your hypothesis testing by stating again what the null and alternative hypotheses are using the symbols we have discussed in class.\n",
    "\n",
    "**Answer**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2:  Calculating the statistic of interest\n",
    "\n",
    "As we have discussed in class, a *statistic* is any number computed from a sample of data. When running a *permutation test* (such as the test we ran in part 2 of lab 6), have a lot of freedom to choose any statistic we would like since we can create a null distribution of any statistic just involves shuffling the data and calculating the statistic we have chosen on the shuffled data. However, when running a parametric hypothesis test, can only use specific statistics for which there is a known parametric probability distribution that we can use as the null distribution. \n",
    "\n",
    "As mentioned above, a parametric test we can use to assess whether two means are the same is the t-test. In the t-test, the statistic we use is a t-statistic, and it is known that when the null hypothesis is true, our t-statistic will come from a parametric distribution called a t-distribution (i.e., our null distribution is a t-distribution). \n",
    "\n",
    "The t-statistic for comparing two means can be calculated as:\n",
    "\n",
    "$t = \\frac{\\bar{x}_1 - \\bar{x}_2}{\\sqrt{\\frac{s^2_1}{n_1} + \\frac{s^2_2}{n_2} }}$\n",
    "\n",
    "where: \n",
    "\n",
    "- $\\bar{x}_1$ and  $\\bar{x}_2$ are the means of sample 1 and sample 2\n",
    "- $s^2_1$ and  $s^2_2$ are the variance of sample 1 and sample 2\n",
    "- $n_1$ and  $n_2$ are the sample sizes of sample 1 and sample 2\n",
    "\n",
    "\n",
    "**Exercise 2.2 (8 points):**  Using the data in `teams_2000` please calculate and print the value of the t-statistic. Save the t-statistic to the name `t_stat` and print its value. \n",
    "\n",
    "Hint: calculating ndarrays called `AL_triples` and `NL_triples` is a good first step prior to calculating the t-statistic.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3:  Creating the null distribution\n",
    "\n",
    "As discussed above, from probability theory we know that if the null hypothesis is true, our t-statistic will come from a t-distribution. A t-distribution is a family of probability distributions that have one parameter called `degrees of freedom`. Once the `degrees of freedom` are set to the appropriate value, we then have a probability distribution we can use as our null distribution. \n",
    "\n",
    "If the samples of data we have come from samples of size $n_1$ and $n_2$, a value for the `degrees of freedom` parameter we can use is the minimum value of $n_1 - 1$ and $n_2 - 1$; i.e., we find the smaller sample size and then we subtract one from it to get the `degrees of freedom` parameter. \n",
    "\n",
    "Let's use Python to calculate the appropriate `degrees of freedom` parameter. We can then use `stats` module in the `scipy` package to get a distribution-t \"random variable object\" in order to plot the appropriate t-distribution that will serve as our null distribution. \n",
    "\n",
    "\n",
    "**Exercise 2.3 (8 points):**  Please complete the following steps to plot an approporiate t-distribution that we serve as a null distribution for analyzing whether the American League and National League hit the same number of triples on average. \n",
    "\n",
    "1. Calculate the appropriate value for the degrees of freedom and save this to the name `df`. Also print this value. \n",
    "\n",
    "2. The code below imports the t-distribution \"random variable object\" to the name `t`, and it also creates a ndarray of x-values that served as the domain when plotting the t-distribution. Please use the `t.pdf(x, df)` method to get the corresponding y values of the density function and save these to the name `t_density`. \n",
    "\n",
    "3. Use Matplotlib `plt.plot()` function to plot the t-distribution density curve. \n",
    "\n",
    "4. Use the axvline `plt.axvline()` function to plot a vertical line at $\\pm$ the observed t-statistic value.\n",
    "\n",
    "5. Based on looking at the figure you created, in the answer section below, please describe what you think the p-value will be.\n",
    "\n",
    "\n",
    "**Answer**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the degrees of freedom and this value to the name df\n",
    "\n",
    "\n",
    "\n",
    "# important the t-distribution \"random variable object\"\n",
    "from scipy.stats import t\n",
    "\n",
    "# creating x values you can use as input when plotting the \n",
    "x = np.linspace(-5, 5, 100)\n",
    "\n",
    "\n",
    "\n",
    "# get the density curve\n",
    "\n",
    "\n",
    "\n",
    "# plt the density curvey\n",
    "\n",
    "\n",
    "\n",
    "# add a vertical line at the observed statistic value\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4:  Calculate the p-value\n",
    "\n",
    "Now we are ready for step 4 where we can calculate the p-value. To do this, please use the `t.cdf(t_stat, df)` method that returns the probability of getting a random t-statistic is less than a specified t-statistic value `t_stat` (from a t-distribution with `df` degrees of freedom); i.e, this  `t.cdf(t_stat, df)` returns $P(X < tstat | df)$. \n",
    "\n",
    "**Exercise 2.4 (8 points):**  Calculate and print out the p-value. Remember you need to look at both tails to get the p-value since this is a two-tailed test.\n",
    "\n",
    "Hints: The t-distribution is symmetric around 0, and $P(X > x) \\approx 1 - P(X < x)$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5:  Make a decision\n",
    "\n",
    "The final step of hypothesis testing (step 5) is to make a decision. Let's do this now.\n",
    "\n",
    "\n",
    "**Exercise 2.5 (5 points):** Based on the p-value you calculated above, what do you conclude? \n",
    "\n",
    "\n",
    "**Answer**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6:  Use built in functions to run a t-test\n",
    "\n",
    "Creating a t-statistic and looking calculate the probability from a t-distribution is a lot of work. To make this easier you could write a function that takes in two samples and does this for you. Fortunately, you don't need to write this function yourself since this function already exists in the `scipy` package. Let's try it out now. \n",
    "\n",
    "**Exercise 2.6 (6 points):** The code below imports the `ttest_ind(sample1, sample2)` function for `scipy`. This function takes in two samples and runs a t-test. Please run this function and print out the t-statistic and p-value it calculates. In the answer section, report if these are the same t-statistic and p-values that you got from the calculations you did above and if you would come to the same conclusion using this function. \n",
    "\n",
    "**Answer**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind as ttest_ind\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3:  Running your own hypothesis test (30 points)\n",
    "\n",
    "Please come up with a question in baseball were you test **either**:\n",
    "\n",
    "a. a population proportion is equal to a particular value, or\n",
    "\n",
    "b. whether two means are the same. \n",
    "\n",
    "\n",
    "Then, go through and run **both** a 1) simulation-based hypothesis test and 2) a parametric based hypothesis test to address this question. Finally, note if both types of tests lead to the same conclusion. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Quote and reaction to Astroball chapter 7 (5 points)\n",
    "\n",
    "Please find an interesting quote from chapter 7 Astroball and then write a ~one paragraph reaction to the quote below.\n",
    "\n",
    "Quote: \n",
    "\n",
    "Reaction: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5. Reflection (3 points)\n",
    "\n",
    "How did this lab go? Please complete the [reflection homework 7](https://yale.instructure.com/courses/65116/quizzes/35188) which is under the quiz section on Canvas to let us know how it went and to reflect on what you learned. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
